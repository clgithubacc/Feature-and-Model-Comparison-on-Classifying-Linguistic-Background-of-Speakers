{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN method to classify speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages:  \n",
    "pyAudioAnalysis can provide feature extraction functions to extract MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import audioFeatureExtraction\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use short-term feature extraction.  \n",
    "It splits the input signal into short-term widnows (frames) and computes a number of features for each frame.  \n",
    "This process leads to a sequence of short-term feature vectors for the whole signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For speakers from 3 different region (Mandarin, Spanish, English), we combine all the features extracted from the sound file and label them into one csv file (dataset.csv)  \n",
    "Label are as follows:  \n",
    "English - 1  \n",
    "Mandarin - 2  \n",
    "Spanish - 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the sound file and label it (English)\n",
    "path = \"unified/eng/\"\n",
    "directory = os.fsencode(path)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "     filename = os.fsdecode(file)\n",
    "     if filename.endswith(\".mp3.wav\"):\n",
    "        # process each sound file individually, read audio file\n",
    "        [Fs, x] = audioBasicIO.readAudioFile(\"unified/eng/\"+filename);\n",
    "        # extract the short term feature sequences for an audio signal, \n",
    "        # using a frame size of 50 msecs and a frame step of 25 msecs (50% overlap)\n",
    "        F, f_names = audioFeatureExtraction.stFeatureExtraction(x, Fs, 0.050*Fs, 0.025*Fs);\n",
    "        df = pd.DataFrame()\n",
    "        df['label'] = []\n",
    "        for i in range(0,22):\n",
    "            df[f_names[i]] = F[i,:]\n",
    "            df['label'] = '1'\n",
    "        with open('dataset.csv', 'a') as f:\n",
    "            df.to_csv(f, header=False)\n",
    "\n",
    "     else:\n",
    "         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the sound file and label it (Mandarin)\n",
    "path = \"unified/man/\"\n",
    "directory = os.fsencode(path)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "     filename = os.fsdecode(file)\n",
    "     if filename.endswith(\".mp3.wav\"):\n",
    "        [Fs, x] = audioBasicIO.readAudioFile(\"unified/man/\"+filename);\n",
    "        F, f_names = audioFeatureExtraction.stFeatureExtraction(x, Fs, 0.050*Fs, 0.025*Fs);\n",
    "        df = pd.DataFrame()\n",
    "        df['label'] = []\n",
    "        for i in range(0,22):\n",
    "            df[f_names[i]] = F[i,:]\n",
    "            df['label'] = '2'\n",
    "        with open('dataset.csv', 'a') as f:\n",
    "            df.to_csv(f, header=False)\n",
    "\n",
    "     else:\n",
    "         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the sound file and label it (Spanish)\n",
    "path = \"unified/span/\"\n",
    "directory = os.fsencode(path)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "     filename = os.fsdecode(file)\n",
    "     if filename.endswith(\".mp3.wav\"):\n",
    "        [Fs, x] = audioBasicIO.readAudioFile(\"unified/span/\"+filename);\n",
    "        F, f_names = audioFeatureExtraction.stFeatureExtraction(x, Fs, 0.050*Fs, 0.025*Fs);\n",
    "        df = pd.DataFrame()\n",
    "        df['label'] = []\n",
    "        for i in range(0,22):\n",
    "            df[f_names[i]] = F[i,:]\n",
    "            df['label'] = '3'\n",
    "        with open('dataset.csv', 'a') as f:\n",
    "            df.to_csv(f, header=False)\n",
    "\n",
    "     else:\n",
    "         continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> This is a sample table for the features extracted:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We have chose 23 features in total:  \n",
    " 1 - Zero Crossing Rate  \n",
    " 2 - Energy  \n",
    " 3 - Entropy of Energy  \n",
    " 4 - Spectral Centroid  \n",
    " 5 - Spectral Spread  \n",
    " 6 - Spectral Entropy  \n",
    " 7 - Spectral Flux  \n",
    " 8 - Spectral Rolloff  \n",
    " 9-21 - MFCCs\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>zcr</th>\n",
       "      <th>energy</th>\n",
       "      <th>energy_entropy</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_spread</th>\n",
       "      <th>spectral_entropy</th>\n",
       "      <th>spectral_flux</th>\n",
       "      <th>spectral_rolloff</th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>mfcc_11</th>\n",
       "      <th>mfcc_12</th>\n",
       "      <th>mfcc_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.317893</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>3.054653</td>\n",
       "      <td>0.287673</td>\n",
       "      <td>0.146611</td>\n",
       "      <td>1.744725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397459</td>\n",
       "      <td>-30.476846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310783</td>\n",
       "      <td>0.399976</td>\n",
       "      <td>-0.026325</td>\n",
       "      <td>0.150470</td>\n",
       "      <td>0.104604</td>\n",
       "      <td>0.139319</td>\n",
       "      <td>-0.028614</td>\n",
       "      <td>0.007746</td>\n",
       "      <td>0.056013</td>\n",
       "      <td>-0.073690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.314260</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>2.193436</td>\n",
       "      <td>0.290566</td>\n",
       "      <td>0.153771</td>\n",
       "      <td>2.013830</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.404719</td>\n",
       "      <td>-29.394962</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.078112</td>\n",
       "      <td>-0.019903</td>\n",
       "      <td>-0.169868</td>\n",
       "      <td>0.673619</td>\n",
       "      <td>0.103392</td>\n",
       "      <td>0.325613</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.564640</td>\n",
       "      <td>0.108138</td>\n",
       "      <td>-0.028476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.316076</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>2.791168</td>\n",
       "      <td>0.329879</td>\n",
       "      <td>0.175049</td>\n",
       "      <td>1.969532</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>-28.992452</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.479832</td>\n",
       "      <td>-0.364813</td>\n",
       "      <td>-0.058583</td>\n",
       "      <td>0.566052</td>\n",
       "      <td>0.141539</td>\n",
       "      <td>0.618688</td>\n",
       "      <td>0.141273</td>\n",
       "      <td>0.575923</td>\n",
       "      <td>0.117765</td>\n",
       "      <td>0.052612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.341508</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>3.246772</td>\n",
       "      <td>0.315275</td>\n",
       "      <td>0.135083</td>\n",
       "      <td>1.770024</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.411978</td>\n",
       "      <td>-29.092591</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.574239</td>\n",
       "      <td>-0.393448</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.543085</td>\n",
       "      <td>0.163311</td>\n",
       "      <td>0.659592</td>\n",
       "      <td>-0.059611</td>\n",
       "      <td>0.482805</td>\n",
       "      <td>0.027010</td>\n",
       "      <td>0.102170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.361490</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>3.077556</td>\n",
       "      <td>0.348398</td>\n",
       "      <td>0.166944</td>\n",
       "      <td>1.694709</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>-29.612030</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164019</td>\n",
       "      <td>-0.336770</td>\n",
       "      <td>-0.257249</td>\n",
       "      <td>0.372231</td>\n",
       "      <td>0.196421</td>\n",
       "      <td>0.551368</td>\n",
       "      <td>-0.263506</td>\n",
       "      <td>0.347963</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>0.043832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label       zcr    energy  energy_entropy  spectral_centroid  \\\n",
       "0     1  0.317893  0.000175        3.054653           0.287673   \n",
       "1     1  0.314260  0.000355        2.193436           0.290566   \n",
       "2     1  0.316076  0.001097        2.791168           0.329879   \n",
       "3     1  0.341508  0.001720        3.246772           0.315275   \n",
       "4     1  0.361490  0.001219        3.077556           0.348398   \n",
       "\n",
       "   spectral_spread  spectral_entropy  spectral_flux  spectral_rolloff  \\\n",
       "0         0.146611          1.744725       0.000000          0.397459   \n",
       "1         0.153771          2.013830       0.002654          0.404719   \n",
       "2         0.175049          1.969532       0.002199          0.413793   \n",
       "3         0.135083          1.770024       0.002143          0.411978   \n",
       "4         0.166944          1.694709       0.002031          0.413793   \n",
       "\n",
       "      mfcc_1  ...    mfcc_4    mfcc_5    mfcc_6    mfcc_7    mfcc_8    mfcc_9  \\\n",
       "0 -30.476846  ... -0.310783  0.399976 -0.026325  0.150470  0.104604  0.139319   \n",
       "1 -29.394962  ... -1.078112 -0.019903 -0.169868  0.673619  0.103392  0.325613   \n",
       "2 -28.992452  ... -1.479832 -0.364813 -0.058583  0.566052  0.141539  0.618688   \n",
       "3 -29.092591  ... -1.574239 -0.393448  0.000549  0.543085  0.163311  0.659592   \n",
       "4 -29.612030  ... -1.164019 -0.336770 -0.257249  0.372231  0.196421  0.551368   \n",
       "\n",
       "    mfcc_10   mfcc_11   mfcc_12   mfcc_13  \n",
       "0 -0.028614  0.007746  0.056013 -0.073690  \n",
       "1  0.002551  0.564640  0.108138 -0.028476  \n",
       "2  0.141273  0.575923  0.117765  0.052612  \n",
       "3 -0.059611  0.482805  0.027010  0.102170  \n",
       "4 -0.263506  0.347963 -0.002334  0.043832  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['label'] = []\n",
    "for i in range(0,21):\n",
    "    df[f_names[i]] = F[i,:]\n",
    "    df['label'] = '1'\n",
    "#     print(df[f_names[i]])\n",
    " \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read file and create dataframe, create training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we used all 22 features extracted from the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv',index_col = 0)\n",
    "x = df[['zcr','energy','energy_entropy','spectral_centroid','spectral_spread','spectral_entropy','spectral_flux','spectral_rolloff','mfcc_1','mfcc_2','mfcc_3','mfcc_4','mfcc_5','mfcc_6','mfcc_7','mfcc_8','mfcc_9','mfcc_10','mfcc_11','mfcc_12','mfcc_13','chroma_1']]\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build KNN Classifier and fit in the model, print the prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compared different prediction accuracy with different numbers of neighbours (3, 5, 7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6196532999164578\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6281119465329992\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63244917850181\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6361180729601782\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the prediction accuracy are pretty much the same and around 0.63. Hower, with number of neighbors increase, the prediction accuracy slightly increases too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we only use mfcc features to train the data to see if there is any difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6235588972431078\n"
     ]
    }
   ],
   "source": [
    "x = df[['mfcc_1','mfcc_2','mfcc_3','mfcc_4','mfcc_5','mfcc_6','mfcc_7','mfcc_8','mfcc_9','mfcc_10','mfcc_11','mfcc_12','mfcc_13']]\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6232873851294904\n"
     ]
    }
   ],
   "source": [
    "x = df[['mfcc_1','mfcc_2','mfcc_3','mfcc_4','mfcc_5','mfcc_6','mfcc_7','mfcc_8','mfcc_9','mfcc_10','mfcc_11','mfcc_12','mfcc_13']]\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3)\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " English(US)       0.66      0.87      0.75     89296\n",
      "     Spanish       0.40      0.11      0.18     15561\n",
      "    Mandarin       0.45      0.26      0.33     38783\n",
      "\n",
      "    accuracy                           0.62    143640\n",
      "   macro avg       0.50      0.41      0.42    143640\n",
      "weighted avg       0.58      0.62      0.58    143640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['English(US)', 'Spanish', 'Mandarin']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there is no such a big difference between using 22 features and 13 mfcc features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize our model we try to normalize the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x-x.mean())/x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.366721</td>\n",
       "      <td>-1.092069</td>\n",
       "      <td>-0.014589</td>\n",
       "      <td>1.673276</td>\n",
       "      <td>1.689741</td>\n",
       "      <td>0.498789</td>\n",
       "      <td>0.098053</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.709506</td>\n",
       "      <td>0.203857</td>\n",
       "      <td>0.143414</td>\n",
       "      <td>0.937126</td>\n",
       "      <td>0.976330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.270844</td>\n",
       "      <td>-0.978530</td>\n",
       "      <td>0.132655</td>\n",
       "      <td>1.527600</td>\n",
       "      <td>1.234789</td>\n",
       "      <td>0.603791</td>\n",
       "      <td>0.326731</td>\n",
       "      <td>1.600346</td>\n",
       "      <td>0.331231</td>\n",
       "      <td>-0.190566</td>\n",
       "      <td>-0.257535</td>\n",
       "      <td>0.723589</td>\n",
       "      <td>0.667438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.279251</td>\n",
       "      <td>-1.086657</td>\n",
       "      <td>-0.022859</td>\n",
       "      <td>1.074859</td>\n",
       "      <td>0.817529</td>\n",
       "      <td>0.501960</td>\n",
       "      <td>0.511110</td>\n",
       "      <td>0.948588</td>\n",
       "      <td>0.028872</td>\n",
       "      <td>-0.248314</td>\n",
       "      <td>-0.264864</td>\n",
       "      <td>0.844052</td>\n",
       "      <td>-0.036431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.377505</td>\n",
       "      <td>-1.026755</td>\n",
       "      <td>-0.088889</td>\n",
       "      <td>1.001777</td>\n",
       "      <td>1.066652</td>\n",
       "      <td>0.437346</td>\n",
       "      <td>0.444312</td>\n",
       "      <td>0.748578</td>\n",
       "      <td>0.550123</td>\n",
       "      <td>0.445194</td>\n",
       "      <td>0.542568</td>\n",
       "      <td>1.509753</td>\n",
       "      <td>0.688372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.436626</td>\n",
       "      <td>-0.865647</td>\n",
       "      <td>0.091126</td>\n",
       "      <td>1.135194</td>\n",
       "      <td>0.953060</td>\n",
       "      <td>0.470755</td>\n",
       "      <td>0.117077</td>\n",
       "      <td>0.961370</td>\n",
       "      <td>0.902763</td>\n",
       "      <td>0.153268</td>\n",
       "      <td>0.745510</td>\n",
       "      <td>1.139576</td>\n",
       "      <td>1.218763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.471196</td>\n",
       "      <td>-0.974707</td>\n",
       "      <td>0.252347</td>\n",
       "      <td>1.405756</td>\n",
       "      <td>0.824157</td>\n",
       "      <td>0.042115</td>\n",
       "      <td>-0.331951</td>\n",
       "      <td>0.352664</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>0.463939</td>\n",
       "      <td>0.391719</td>\n",
       "      <td>0.991807</td>\n",
       "      <td>0.845736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.449797</td>\n",
       "      <td>-0.722354</td>\n",
       "      <td>0.024903</td>\n",
       "      <td>1.514353</td>\n",
       "      <td>1.350594</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.662948</td>\n",
       "      <td>0.608575</td>\n",
       "      <td>0.414390</td>\n",
       "      <td>0.436025</td>\n",
       "      <td>0.692049</td>\n",
       "      <td>1.277221</td>\n",
       "      <td>0.787689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.639612</td>\n",
       "      <td>-0.761026</td>\n",
       "      <td>0.160842</td>\n",
       "      <td>1.606279</td>\n",
       "      <td>1.459162</td>\n",
       "      <td>0.600331</td>\n",
       "      <td>0.600508</td>\n",
       "      <td>0.763964</td>\n",
       "      <td>-0.224947</td>\n",
       "      <td>-0.072366</td>\n",
       "      <td>0.984137</td>\n",
       "      <td>1.199470</td>\n",
       "      <td>0.832116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.714263</td>\n",
       "      <td>-0.951005</td>\n",
       "      <td>0.052317</td>\n",
       "      <td>1.361294</td>\n",
       "      <td>1.262125</td>\n",
       "      <td>0.843315</td>\n",
       "      <td>-0.014770</td>\n",
       "      <td>0.674308</td>\n",
       "      <td>-0.340387</td>\n",
       "      <td>-0.213699</td>\n",
       "      <td>0.702508</td>\n",
       "      <td>1.160154</td>\n",
       "      <td>0.911240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.552914</td>\n",
       "      <td>-0.987817</td>\n",
       "      <td>0.078971</td>\n",
       "      <td>1.108526</td>\n",
       "      <td>0.782073</td>\n",
       "      <td>0.700300</td>\n",
       "      <td>1.082980</td>\n",
       "      <td>1.497345</td>\n",
       "      <td>0.573797</td>\n",
       "      <td>0.119164</td>\n",
       "      <td>0.578165</td>\n",
       "      <td>1.367355</td>\n",
       "      <td>1.217061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mfcc1     mfcc2     mfcc3     mfcc4     mfcc5     mfcc6     mfcc7  \\\n",
       "0 -1.366721 -1.092069 -0.014589  1.673276  1.689741  0.498789  0.098053   \n",
       "1 -1.270844 -0.978530  0.132655  1.527600  1.234789  0.603791  0.326731   \n",
       "2 -1.279251 -1.086657 -0.022859  1.074859  0.817529  0.501960  0.511110   \n",
       "3 -1.377505 -1.026755 -0.088889  1.001777  1.066652  0.437346  0.444312   \n",
       "4 -1.436626 -0.865647  0.091126  1.135194  0.953060  0.470755  0.117077   \n",
       "5 -1.471196 -0.974707  0.252347  1.405756  0.824157  0.042115 -0.331951   \n",
       "6 -1.449797 -0.722354  0.024903  1.514353  1.350594  0.679278  0.662948   \n",
       "7 -1.639612 -0.761026  0.160842  1.606279  1.459162  0.600331  0.600508   \n",
       "8 -1.714263 -0.951005  0.052317  1.361294  1.262125  0.843315 -0.014770   \n",
       "9 -1.552914 -0.987817  0.078971  1.108526  0.782073  0.700300  1.082980   \n",
       "\n",
       "      mfcc8     mfcc9    mfcc10    mfcc11    mfcc12    mfcc13  \n",
       "0  0.711796  0.709506  0.203857  0.143414  0.937126  0.976330  \n",
       "1  1.600346  0.331231 -0.190566 -0.257535  0.723589  0.667438  \n",
       "2  0.948588  0.028872 -0.248314 -0.264864  0.844052 -0.036431  \n",
       "3  0.748578  0.550123  0.445194  0.542568  1.509753  0.688372  \n",
       "4  0.961370  0.902763  0.153268  0.745510  1.139576  1.218763  \n",
       "5  0.352664  0.612725  0.463939  0.391719  0.991807  0.845736  \n",
       "6  0.608575  0.414390  0.436025  0.692049  1.277221  0.787689  \n",
       "7  0.763964 -0.224947 -0.072366  0.984137  1.199470  0.832116  \n",
       "8  0.674308 -0.340387 -0.213699  0.702508  1.160154  0.911240  \n",
       "9  1.497345  0.573797  0.119164  0.578165  1.367355  1.217061  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize mfcc features\n",
    "dataframe = pd.read_csv('dataset.csv',index_col = 0)\n",
    "x = dataframe[['mfcc_1','mfcc_2','mfcc_3','mfcc_4','mfcc_5','mfcc_6','mfcc_7','mfcc_8','mfcc_9','mfcc_10','mfcc_11','mfcc_12','mfcc_13']]\n",
    "normalized_x = pd.DataFrame()\n",
    "count = 1\n",
    "for i in x:\n",
    "    i = normalize(dataframe[i])\n",
    "    normalized_x[\"mfcc\"+ str(count)] = i\n",
    "    count = count + 1\n",
    "\n",
    "normalized_x.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the table that contains 478800 entries of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>zcr</th>\n",
       "      <th>energy</th>\n",
       "      <th>energy_entropy</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_spread</th>\n",
       "      <th>spectral_entropy</th>\n",
       "      <th>spectral_flux</th>\n",
       "      <th>spectral_rolloff</th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>mfcc_11</th>\n",
       "      <th>mfcc_12</th>\n",
       "      <th>mfcc_13</th>\n",
       "      <th>chroma_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>4.788000e+05</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>478800.000000</td>\n",
       "      <td>4.788000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.648333</td>\n",
       "      <td>0.138316</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>3.072952</td>\n",
       "      <td>0.214487</td>\n",
       "      <td>0.200836</td>\n",
       "      <td>8.287646e-01</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.206260</td>\n",
       "      <td>-26.793379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.323530</td>\n",
       "      <td>0.053969</td>\n",
       "      <td>-0.073894</td>\n",
       "      <td>-0.008552</td>\n",
       "      <td>-0.095378</td>\n",
       "      <td>-0.071741</td>\n",
       "      <td>-0.113041</td>\n",
       "      <td>-0.057503</td>\n",
       "      <td>-0.105271</td>\n",
       "      <td>2.034716e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.876355</td>\n",
       "      <td>0.147643</td>\n",
       "      <td>0.018931</td>\n",
       "      <td>0.228431</td>\n",
       "      <td>0.131248</td>\n",
       "      <td>0.049075</td>\n",
       "      <td>7.668584e-01</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>0.238092</td>\n",
       "      <td>2.420032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554736</td>\n",
       "      <td>0.465873</td>\n",
       "      <td>0.415311</td>\n",
       "      <td>0.362158</td>\n",
       "      <td>0.343331</td>\n",
       "      <td>0.327139</td>\n",
       "      <td>0.316236</td>\n",
       "      <td>0.319651</td>\n",
       "      <td>0.314870</td>\n",
       "      <td>3.515638e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.333757</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>0.030122</td>\n",
       "      <td>7.503214e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-47.762011</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.267421</td>\n",
       "      <td>-2.172960</td>\n",
       "      <td>-2.060405</td>\n",
       "      <td>-1.943886</td>\n",
       "      <td>-1.837495</td>\n",
       "      <td>-1.782610</td>\n",
       "      <td>-1.714220</td>\n",
       "      <td>-1.662052</td>\n",
       "      <td>-1.764887</td>\n",
       "      <td>2.274218e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047230</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>2.986923</td>\n",
       "      <td>0.127713</td>\n",
       "      <td>0.166846</td>\n",
       "      <td>2.111611e-01</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.045372</td>\n",
       "      <td>-28.399418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690973</td>\n",
       "      <td>-0.255144</td>\n",
       "      <td>-0.350322</td>\n",
       "      <td>-0.241125</td>\n",
       "      <td>-0.318435</td>\n",
       "      <td>-0.277326</td>\n",
       "      <td>-0.306589</td>\n",
       "      <td>-0.250215</td>\n",
       "      <td>-0.294183</td>\n",
       "      <td>2.434024e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>3.145891</td>\n",
       "      <td>0.164899</td>\n",
       "      <td>0.196857</td>\n",
       "      <td>5.521587e-01</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.090744</td>\n",
       "      <td>-26.552168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311706</td>\n",
       "      <td>0.049421</td>\n",
       "      <td>-0.067579</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>-0.082891</td>\n",
       "      <td>-0.059318</td>\n",
       "      <td>-0.093479</td>\n",
       "      <td>-0.037107</td>\n",
       "      <td>-0.084058</td>\n",
       "      <td>6.756622e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.158038</td>\n",
       "      <td>0.014707</td>\n",
       "      <td>3.233517</td>\n",
       "      <td>0.254569</td>\n",
       "      <td>0.230491</td>\n",
       "      <td>1.247080e+00</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.261343</td>\n",
       "      <td>-25.010996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053639</td>\n",
       "      <td>0.353329</td>\n",
       "      <td>0.204030</td>\n",
       "      <td>0.233180</td>\n",
       "      <td>0.137778</td>\n",
       "      <td>0.145825</td>\n",
       "      <td>0.099508</td>\n",
       "      <td>0.153462</td>\n",
       "      <td>0.101314</td>\n",
       "      <td>2.042029e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.897366</td>\n",
       "      <td>0.619221</td>\n",
       "      <td>3.321075</td>\n",
       "      <td>0.833006</td>\n",
       "      <td>0.400802</td>\n",
       "      <td>3.271169e+00</td>\n",
       "      <td>0.445985</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>-20.293946</td>\n",
       "      <td>...</td>\n",
       "      <td>2.297223</td>\n",
       "      <td>2.377265</td>\n",
       "      <td>2.052533</td>\n",
       "      <td>2.107679</td>\n",
       "      <td>1.532954</td>\n",
       "      <td>1.954015</td>\n",
       "      <td>1.710319</td>\n",
       "      <td>1.778261</td>\n",
       "      <td>1.557266</td>\n",
       "      <td>3.261622e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               label            zcr         energy  energy_entropy  \\\n",
       "count  478800.000000  478800.000000  478800.000000   478800.000000   \n",
       "mean        1.648333       0.138316       0.012083        3.072952   \n",
       "std         0.876355       0.147643       0.018931        0.228431   \n",
       "min         1.000000       0.000000       0.000004        0.333757   \n",
       "25%         1.000000       0.047230       0.001421        2.986923   \n",
       "50%         1.000000       0.076294       0.005154        3.145891   \n",
       "75%         3.000000       0.158038       0.014707        3.233517   \n",
       "max         3.000000       0.897366       0.619221        3.321075   \n",
       "\n",
       "       spectral_centroid  spectral_spread  spectral_entropy  spectral_flux  \\\n",
       "count      478800.000000    478800.000000      4.788000e+05  478800.000000   \n",
       "mean            0.214487         0.200836      8.287646e-01       0.006608   \n",
       "std             0.131248         0.049075      7.668584e-01       0.007056   \n",
       "min             0.003172         0.030122      7.503214e-07       0.000000   \n",
       "25%             0.127713         0.166846      2.111611e-01       0.003090   \n",
       "50%             0.164899         0.196857      5.521587e-01       0.005025   \n",
       "75%             0.254569         0.230491      1.247080e+00       0.008010   \n",
       "max             0.833006         0.400802      3.271169e+00       0.445985   \n",
       "\n",
       "       spectral_rolloff         mfcc_1  ...         mfcc_5         mfcc_6  \\\n",
       "count     478800.000000  478800.000000  ...  478800.000000  478800.000000   \n",
       "mean           0.206260     -26.793379  ...      -0.323530       0.053969   \n",
       "std            0.238092       2.420032  ...       0.554736       0.465873   \n",
       "min            0.000000     -47.762011  ...      -3.267421      -2.172960   \n",
       "25%            0.045372     -28.399418  ...      -0.690973      -0.255144   \n",
       "50%            0.090744     -26.552168  ...      -0.311706       0.049421   \n",
       "75%            0.261343     -25.010996  ...       0.053639       0.353329   \n",
       "max            0.965517     -20.293946  ...       2.297223       2.377265   \n",
       "\n",
       "              mfcc_7         mfcc_8         mfcc_9        mfcc_10  \\\n",
       "count  478800.000000  478800.000000  478800.000000  478800.000000   \n",
       "mean       -0.073894      -0.008552      -0.095378      -0.071741   \n",
       "std         0.415311       0.362158       0.343331       0.327139   \n",
       "min        -2.060405      -1.943886      -1.837495      -1.782610   \n",
       "25%        -0.350322      -0.241125      -0.318435      -0.277326   \n",
       "50%        -0.067579       0.001638      -0.082891      -0.059318   \n",
       "75%         0.204030       0.233180       0.137778       0.145825   \n",
       "max         2.052533       2.107679       1.532954       1.954015   \n",
       "\n",
       "             mfcc_11        mfcc_12        mfcc_13      chroma_1  \n",
       "count  478800.000000  478800.000000  478800.000000  4.788000e+05  \n",
       "mean       -0.113041      -0.057503      -0.105271  2.034716e-02  \n",
       "std         0.316236       0.319651       0.314870  3.515638e-02  \n",
       "min        -1.714220      -1.662052      -1.764887  2.274218e-11  \n",
       "25%        -0.306589      -0.250215      -0.294183  2.434024e-03  \n",
       "50%        -0.093479      -0.037107      -0.084058  6.756622e-03  \n",
       "75%         0.099508       0.153462       0.101314  2.042029e-02  \n",
       "max         1.710319       1.778261       1.557266  3.261622e-01  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataframe['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.632010582010582\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalized_x, y, stratify=y, test_size=0.3)\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " English(US)       0.67      0.87      0.76     89296\n",
      "     Spanish       0.43      0.13      0.20     15561\n",
      "    Mandarin       0.47      0.27      0.35     38783\n",
      "\n",
      "    accuracy                           0.63    143640\n",
      "   macro avg       0.52      0.43      0.44    143640\n",
      "weighted avg       0.59      0.63      0.59    143640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['English(US)', 'Spanish', 'Mandarin']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataframe[['mfcc_1','mfcc_2','mfcc_3','mfcc_4','mfcc_5','mfcc_6','mfcc_7','mfcc_8','mfcc_9','mfcc_10','mfcc_11','mfcc_12','mfcc_13']]\n",
    "normalized_x = pd.DataFrame()\n",
    "count = 1\n",
    "for i in x:\n",
    "    i = normalize(dataframe[i])\n",
    "    normalized_x[\"mfcc\"+ str(count)] = i\n",
    "    count = count + 1\n",
    "y = dataframe['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6360763018657756\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalized_x, y, test_size=0.15)\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare the model with normalized input with the unnormalized input, prediction accuracy is still very similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also tried to split the test data by audio file, for example, we find each audio file extracts 798 data records, we split the test data by 30% of English,Mandarin,Spanish audio files, so 112,19,49 files will be taken as test audio files, that's 180 in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mfcc1     mfcc2     mfcc3     mfcc4     mfcc5     mfcc6     mfcc7  \\\n",
      "0   -0.172904  0.984969  0.910135  0.956940 -1.463915 -0.856273  0.767871   \n",
      "1    0.564196  0.447614  0.377670  0.307957 -1.485418 -0.776060  0.296891   \n",
      "2    0.543723  0.545370  0.898581  0.794602 -1.879760 -0.382586 -0.119853   \n",
      "3    0.633786  0.334014  1.081994  0.238636 -1.226101  0.180228 -0.615795   \n",
      "4    0.444130  0.245998  1.433295  0.073945 -0.758072  0.605848  0.058155   \n",
      "5    0.252314  0.508330  1.785225 -0.698013 -1.205473 -0.480411 -0.878064   \n",
      "6    0.136066  0.107140  0.926715 -0.171600  0.178284  0.040163 -0.612684   \n",
      "7   -0.727852 -0.060058  1.411944  0.412422 -0.971629  0.348483 -0.255636   \n",
      "8   -0.648311 -0.692491  0.031363  0.185709 -0.824808 -0.208398 -0.029135   \n",
      "9   -0.760560 -0.659546  0.029595  1.554505 -0.309935  0.295719  0.796292   \n",
      "10  -0.585475 -0.374795 -1.092678  0.856990 -0.920616  0.079916  1.866051   \n",
      "11   0.205345  0.738155 -1.646673 -0.142941 -0.194923 -0.808480  2.858714   \n",
      "12   0.977173  0.625041 -1.424225 -0.221155  0.340317 -0.867194  1.037756   \n",
      "13   1.574401 -0.063689 -1.887638 -1.061984  0.591820 -0.093539  0.780297   \n",
      "14   1.725916  0.267481 -1.794266 -1.011306  1.042143 -0.536574  0.692262   \n",
      "15   1.491615 -0.101904 -2.082220 -1.088422  1.614306 -0.621297  1.083523   \n",
      "16   1.608458  0.749189 -2.081849 -1.612788  1.700418 -0.521782  1.000579   \n",
      "17   1.812450 -0.025756 -1.830019 -1.334922  0.458816  0.145567  0.707033   \n",
      "18   1.637289  0.575870 -1.787888 -1.698304  0.655099  0.869206  0.354057   \n",
      "19   1.258275 -0.009877 -1.868439 -1.425561  0.431907  0.525617  0.567096   \n",
      "20   0.928150  0.391376 -1.532866 -1.145069  0.329517  0.273147  0.699899   \n",
      "21  -0.235647  1.008727 -1.202727 -1.419517  1.370132 -0.346212  0.984508   \n",
      "22  -0.750702  0.865576 -1.122689 -1.938071  1.686516 -2.088516  0.373071   \n",
      "23  -1.092920  0.285917 -0.444441 -1.022043  1.494790 -1.711985  0.942672   \n",
      "24  -1.512009  0.083807 -0.203471 -0.676134  1.162322 -2.355855  0.515019   \n",
      "25  -0.846132  0.128352 -0.876745 -1.120248 -0.880435 -1.299256  1.803021   \n",
      "26   0.093050  0.421110 -0.642627 -0.180145 -1.883180 -2.035805  2.083037   \n",
      "27   1.004611  0.265715 -1.146011 -0.678612 -1.622165 -0.368926  3.015212   \n",
      "28   1.363899  0.434599 -1.143938 -0.645386 -1.213774 -0.447070  3.553745   \n",
      "29   1.647388  0.276932 -1.382470 -0.815934 -0.711477 -0.255260  3.143355   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "768 -0.955222 -2.743858  0.316761 -0.963755 -0.338102  0.152295 -0.703522   \n",
      "769 -1.014588 -3.825508  0.231277 -0.366880  0.180688  0.546291  0.165295   \n",
      "770 -0.896652 -3.881833  0.118128 -0.425985 -0.248244  0.256228  0.033722   \n",
      "771 -0.548408 -2.926684 -0.043439 -0.404339 -0.364418  0.799011  0.819923   \n",
      "772 -0.187272 -1.933029 -0.474586 -0.339623 -0.636866  0.736909  1.211061   \n",
      "773  0.136344 -1.450037 -0.681964  0.396435 -0.956219  1.256647  0.937867   \n",
      "774  0.322385 -1.651041 -0.504903 -0.090315 -1.325019  1.505242  0.164525   \n",
      "775  0.393296 -1.799992 -0.140506 -0.326275 -0.922651  0.841466 -0.428062   \n",
      "776  0.162798 -1.600414  0.504234 -1.232999 -0.892240  0.587923 -0.348442   \n",
      "777 -0.025969 -1.114586  0.869998 -1.557798 -0.488220 -0.103625 -0.294899   \n",
      "778 -0.232248 -0.585404  0.969619 -1.314031  0.072606 -0.515236 -0.164923   \n",
      "779 -0.688463 -0.388672  0.593502 -1.618700 -0.596618 -0.613508 -0.229261   \n",
      "780 -0.949269 -0.450006  0.676903 -1.104449  0.408056 -0.229929  0.378394   \n",
      "781 -1.376401 -1.681124  0.500882 -0.796969  1.096518 -0.862269  0.688670   \n",
      "782 -1.695789 -1.938682  0.619290 -0.431729  1.582386 -0.502881  0.339433   \n",
      "783 -1.778027 -2.233654  0.211559 -0.388903  1.339596 -0.029104  0.702279   \n",
      "784 -1.240919 -2.001458  0.644144 -0.868394  0.286634  0.015064 -0.068089   \n",
      "785 -0.221498 -1.618774  1.029955 -1.913720 -0.834088  0.075569 -0.504717   \n",
      "786  0.044833 -1.840722  1.070655 -2.450859 -1.215970 -0.240365 -0.294788   \n",
      "787  0.130702 -2.309371  1.084353 -2.228296 -1.427723 -0.667454 -0.725789   \n",
      "788  0.064800 -1.991804  1.608111 -2.337953 -1.160251 -0.660519 -0.857702   \n",
      "789 -0.168864 -1.656181  1.821326 -2.495121 -0.345248 -0.521949 -1.503502   \n",
      "790 -0.508036 -1.833125  1.646420 -2.148965  0.227661 -1.524416 -2.020423   \n",
      "791 -0.748053 -2.090937  1.498801 -1.638727  0.080689 -1.836684 -1.544165   \n",
      "792 -0.738687 -2.782329  1.214012 -1.309158  0.139537 -1.589880 -0.686362   \n",
      "793 -0.786052 -3.407404  1.092820 -1.142924  0.492617 -0.979584 -0.386291   \n",
      "794 -0.767033 -3.736337  0.795764 -0.914329  1.033407 -0.054721  0.061809   \n",
      "795 -0.902966 -3.890422  0.592241 -1.281562  0.719415  0.022097  0.186096   \n",
      "796 -1.285505 -3.917514  0.518834 -1.311551  0.931079  0.408367  0.022642   \n",
      "797 -1.595289 -3.581403  0.643778 -1.280453  0.780060  0.093656 -0.171728   \n",
      "\n",
      "        mfcc8     mfcc9    mfcc10    mfcc11    mfcc12    mfcc13  \n",
      "0   -1.551721  0.955834 -0.678125  0.144991  0.754798  1.038895  \n",
      "1    0.037766  1.490466  0.670298 -0.028079  1.178834  0.644713  \n",
      "2   -0.970653  0.969949 -0.135850 -0.258178  0.595887  1.191047  \n",
      "3   -0.468445  0.601375  0.729879  0.273521 -0.073206 -0.094860  \n",
      "4    0.354711  0.604972  1.317945  0.295925  0.041942 -0.499555  \n",
      "5    0.262704 -0.695714  0.175756 -0.551734 -0.531621 -0.164396  \n",
      "6    0.674441 -0.155523  0.463317  0.172847 -0.058516 -0.997245  \n",
      "7    0.226252  0.110678  0.022431  0.234540 -0.487706 -0.359282  \n",
      "8   -0.171015  0.801573  0.301327 -0.356954 -1.226157 -0.703698  \n",
      "9   -1.002926  0.617764  0.462793 -0.603326 -0.541934  0.812943  \n",
      "10  -1.917936 -0.903255  0.404070 -0.584261 -0.802149  0.318324  \n",
      "11  -0.367176 -0.661157  0.289684 -1.606031  0.399017  0.433781  \n",
      "12  -0.760418 -1.122443  0.732354 -0.636515  0.950905  0.340565  \n",
      "13  -0.309587 -0.685652  0.241564  0.756298  1.678376 -0.031381  \n",
      "14   0.322891 -0.746782 -0.898375 -0.419894  1.129966 -0.760394  \n",
      "15   0.413334 -1.230307 -1.198938 -0.569772  0.402106 -0.703986  \n",
      "16  -0.022017 -0.085205 -0.147732 -0.045931  1.352954 -0.499116  \n",
      "17  -0.351025 -0.587919 -0.348949  0.980516  1.309471 -0.121868  \n",
      "18  -0.780894 -0.160835 -0.218246 -0.000971  1.083224 -0.254778  \n",
      "19   0.523269  1.237880  1.204561  1.158724  0.621564 -0.025987  \n",
      "20   0.574993  0.523422 -0.822104  0.138380  0.772356 -0.006440  \n",
      "21   0.521188 -0.093978 -0.509130  0.738801  1.858469  1.252191  \n",
      "22  -0.784183  1.097500  0.370387  1.575564  2.871210  0.647184  \n",
      "23  -1.123212 -0.062063 -1.082986  0.508677  2.390053  0.701164  \n",
      "24  -1.172358  0.969560 -0.939386  0.218239  2.526085  0.086890  \n",
      "25  -1.445767  0.457749 -0.543022 -1.857706  1.712587 -0.227058  \n",
      "26  -1.456244 -0.159832  1.205118 -2.833787  0.715162 -0.825390  \n",
      "27  -1.705006  0.274441  1.243716 -2.159293  1.843182  0.583295  \n",
      "28  -1.969765 -0.066980  1.221142 -1.591228  1.592002 -0.001531  \n",
      "29  -1.728531 -0.460113  1.395300 -1.205628  0.977591  1.531795  \n",
      "..        ...       ...       ...       ...       ...       ...  \n",
      "768  0.355568  2.249474  0.275670  1.688042  0.092352  0.508372  \n",
      "769 -0.374891  1.085517 -0.808611  0.453627 -0.352702  0.915562  \n",
      "770 -1.213097  0.749531 -0.852926  0.578623 -0.441360  0.700745  \n",
      "771 -0.805580  1.261110 -0.240462  1.692940  1.107250  1.413393  \n",
      "772 -0.219938  2.565729 -0.838383  0.117825  0.990806  1.096572  \n",
      "773  0.168332  1.962214 -1.651088  0.676218 -0.237988  0.667561  \n",
      "774 -0.160998  1.449075 -0.343801  1.047179 -0.172312  0.695754  \n",
      "775 -0.673765  0.707705  0.352121  1.025809  0.075456  0.157233  \n",
      "776 -0.149731  0.401563  1.074922  1.312389  0.510443 -0.240593  \n",
      "777 -0.086553 -0.339481  1.274388  1.209574  1.087351  0.348360  \n",
      "778  0.302526  0.186821  1.370143  0.432720 -0.731160  0.397789  \n",
      "779  0.316797  1.458558  1.741197  2.280835  0.749739 -0.146762  \n",
      "780 -0.236688  1.197672  0.022006  1.945718  0.190261  0.043133  \n",
      "781  0.520467  2.197730  0.955786  2.529822  1.154910  0.534401  \n",
      "782 -0.092007  1.506192 -0.253969  2.216542  0.911161  0.827680  \n",
      "783  0.798913  2.191102  0.291464  2.849347 -0.284376  0.600527  \n",
      "784  1.121452  0.619571  0.386044  1.341565 -0.203200 -0.018343  \n",
      "785  1.863842  0.112003  0.422504  0.887969  0.006316 -0.108368  \n",
      "786  1.477797  0.263328  1.392428  1.351519 -0.157492 -0.685751  \n",
      "787  1.457358  0.489287  1.430458  1.606187  0.456877  0.146554  \n",
      "788  1.701368 -0.299910  1.279019  1.348570  0.325079  0.482812  \n",
      "789  1.488418 -1.088498  1.001435  1.502199  0.891639  0.969448  \n",
      "790  0.442682 -1.487641  0.453253  1.155534  1.381169  0.662643  \n",
      "791 -0.161737 -0.434730  0.887609  1.349070  1.528078  0.405875  \n",
      "792 -0.332486  0.942240  0.440055  1.022394  0.782241  1.081236  \n",
      "793 -0.120297  1.205303  0.484637  1.761315 -0.237953  1.356675  \n",
      "794 -0.105387  1.178302 -0.096854  1.812067 -0.464014  0.553579  \n",
      "795  0.035373  1.275944 -0.218155  2.041442 -0.016169  1.079271  \n",
      "796 -0.298976  1.532685 -0.622451  2.901734 -0.541445  1.147410  \n",
      "797 -0.484130  1.607779 -0.175888  1.935011 -1.024011  1.162348  \n",
      "\n",
      "[90174 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "eng_x_test = normalized_x.iloc[0:89376]\n",
    "eng_x_train = normalized_x.iloc[89376:297654]\n",
    "man_x_test = normalized_x.iloc[297654:312816]\n",
    "man_x_train = normalized_x.iloc[312816:349524]\n",
    "span_x_test = normalized_x.iloc[349524:388626]\n",
    "span_x_train = normalized_x.iloc[388626:478800]\n",
    "print(span_x_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalized_x.iloc[np.r_[89376:297654, 312816:349524, 388626:478800 ]]\n",
    "y_train = y.iloc[np.r_[89376:297654, 312816:349524, 388626:478800 ]]\n",
    "X_test = normalized_x.iloc[np.r_[0:89376, 297654:312816, 349524:388626 ]]\n",
    "y_test = y.iloc[np.r_[0:89376, 297654:312816, 349524:388626 ]]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find the prediciton of each time segment, then take the mode of the entire time frame of the audio file to determine the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6277777777777778\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_realtest = []\n",
    "y_pred = []\n",
    "for i in range(0,180):\n",
    "    y_predpiece = knn.predict(X_test.iloc[(i*797):(i*797+797)])\n",
    "    counts = np.bincount(y_predpiece)\n",
    "    # get mode\n",
    "    y_predmode = np.argmax(counts)\n",
    "#     print(y_predmode)\n",
    "    y_pred.append(y_predmode)\n",
    "    y_realtest.append(y_test.iloc[i*797])\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_realtest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(y_realtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " English(US)       0.63      1.00      0.77       113\n",
      "     Spanish       0.00      0.00      0.00        19\n",
      "    Mandarin       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.63       180\n",
      "   macro avg       0.21      0.33      0.26       180\n",
      "weighted avg       0.39      0.63      0.48       180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tang/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['English(US)', 'Spanish', 'Mandarin']\n",
    "print(classification_report(y_realtest, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we still find the accuracy remains the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, we find that all the test y are classified into english label so we wonder if the English audio file are too many. So we average the number of audio file to take 19 test audio files from each language region and 46 training audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_x_test = normalized_x.iloc[0:15162]\n",
    "eng_x_train = normalized_x.iloc[15162:51870]\n",
    "man_x_test = normalized_x.iloc[297654:312816]\n",
    "man_x_train = normalized_x.iloc[312816:349524]\n",
    "span_x_test = normalized_x.iloc[349524:364686]\n",
    "span_x_train = normalized_x.iloc[364686:401394]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalized_x.iloc[np.r_[15162:51870, 312816:349524, 364686:401394 ]]\n",
    "y_train = y.iloc[np.r_[15162:51870, 312816:349524, 364686:401394 ]]\n",
    "X_test = normalized_x.iloc[np.r_[0:15162, 297654:312816, 349524:364686 ]]\n",
    "y_test = y.iloc[np.r_[0:15162, 297654:312816, 349524:364686 ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40350877192982454\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_realtest = []\n",
    "y_pred = []\n",
    "for i in range(0,57):\n",
    "    y_predpiece = knn.predict(X_test.iloc[(i*797):(i*797+797)])\n",
    "    counts = np.bincount(y_predpiece)\n",
    "    # get mode\n",
    "    y_predmode = np.argmax(counts)\n",
    "#     print(y_predmode)\n",
    "    y_pred.append(y_predmode)\n",
    "    y_realtest.append(y_test.iloc[i*797])\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_realtest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(y_realtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 1, 2, 3, 2, 3, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 1, 3, 2, 3, 3, 2, 2, 2, 3, 2, 3, 1, 1, 1, 3, 3, 3, 1, 2, 2, 3, 2, 3, 3, 2, 3, 1, 3, 2, 3, 3, 1, 2, 1, 2, 1, 2, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " English(US)       0.41      0.65      0.50        20\n",
      "     Spanish       0.38      0.32      0.34        19\n",
      "    Mandarin       0.44      0.22      0.30        18\n",
      "\n",
      "    accuracy                           0.40        57\n",
      "   macro avg       0.41      0.40      0.38        57\n",
      "weighted avg       0.41      0.40      0.38        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['English(US)', 'Spanish', 'Mandarin']\n",
    "print(classification_report(y_realtest, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found the accuracy are even lower than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     English       0.63      0.98      0.77     98093\n",
      "    Mandarin       0.52      0.03      0.05     17245\n",
      "     Spanish       0.52      0.07      0.12     42666\n",
      "\n",
      "    accuracy                           0.63    158004\n",
      "   macro avg       0.56      0.36      0.31    158004\n",
      "weighted avg       0.59      0.63      0.52    158004\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_x, y, test_size=0.33)\n",
    "xgb_c = XGBClassifier(max_depth=10, n_estimators=100, n_jobs=-1, num_class=3, subsample=0.6) \n",
    "xgb_c.fit(X_train, y_train.ravel())\n",
    "y_pred = xgb_c.predict(X_test) ##predict\n",
    "\n",
    "y_true = y_test\n",
    "target_names = ['English', 'Mandarin', 'Spanish']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_plot = sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
